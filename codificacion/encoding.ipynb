{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9563819a-f92b-4768-b241-746dd37bd595",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 323253504 into shape (154224,524)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 42\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m pd\u001b[38;5;241m.\u001b[39mDataFrame(reshaped_data, columns\u001b[38;5;241m=\u001b[39mcolumns)\n\u001b[1;32m     41\u001b[0m \u001b[38;5;66;03m# Volver a organizar los datos codificados\u001b[39;00m\n\u001b[0;32m---> 42\u001b[0m encoded_REF_df \u001b[38;5;241m=\u001b[39m \u001b[43mreshape_encoded\u001b[49m\u001b[43m(\u001b[49m\u001b[43mref_encoded\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_len_REF\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnucleotides\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     43\u001b[0m encoded_ALT_df \u001b[38;5;241m=\u001b[39m reshape_encoded(alt_encoded, max_len_ALT, nucleotides)\n\u001b[1;32m     45\u001b[0m \u001b[38;5;66;03m# Concatenar con el DataFrame original y eliminar las columnas originales\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[10], line 37\u001b[0m, in \u001b[0;36mreshape_encoded\u001b[0;34m(encoded_data, max_len, nucleotides)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mreshape_encoded\u001b[39m(encoded_data, max_len, nucleotides):\n\u001b[1;32m     36\u001b[0m     num_samples \u001b[38;5;241m=\u001b[39m encoded_data\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m (\u001b[38;5;28mlen\u001b[39m(nucleotides) \u001b[38;5;241m*\u001b[39m max_len)\n\u001b[0;32m---> 37\u001b[0m     reshaped_data \u001b[38;5;241m=\u001b[39m \u001b[43mencoded_data\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum_samples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mnucleotides\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmax_len\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     38\u001b[0m     columns \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbase_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbase\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_pos_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m base \u001b[38;5;129;01min\u001b[39;00m nucleotides \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(max_len)]\n\u001b[1;32m     39\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m pd\u001b[38;5;241m.\u001b[39mDataFrame(reshaped_data, columns\u001b[38;5;241m=\u001b[39mcolumns)\n",
      "\u001b[0;31mValueError\u001b[0m: cannot reshape array of size 323253504 into shape (154224,524)"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "# Cargar los archivos\n",
    "variaciones = pd.read_csv('/home/ec2-user/SageMaker/segundo intento/final2/variaciones.csv')\n",
    "\n",
    "# Filtrar secuencias válidas\n",
    "def clean_sequence(sequence):\n",
    "    return ''.join([base if base in nucleotides else '' for base in sequence])\n",
    "\n",
    "# Definir nucleótidos válidos\n",
    "nucleotides = ['A', 'C', 'G', 'T']\n",
    "\n",
    "# Limpiar las secuencias\n",
    "variaciones['REF'] = variaciones['REF'].apply(clean_sequence)\n",
    "variaciones['ALT'] = variaciones['ALT'].apply(clean_sequence)\n",
    "\n",
    "# Convertir las secuencias a listas de caracteres\n",
    "ref_df = pd.DataFrame(variaciones['REF'].apply(list).tolist())\n",
    "alt_df = pd.DataFrame(variaciones['ALT'].apply(list).tolist())\n",
    "\n",
    "# Crear y ajustar el codificador One-Hot\n",
    "encoder = OneHotEncoder(categories=[nucleotides], sparse_output=False, handle_unknown='ignore')\n",
    "\n",
    "# Aplanar DataFrames y aplicar codificación One-Hot\n",
    "ref_encoded = encoder.fit_transform(ref_df.fillna('').values.flatten().reshape(-1, 1))\n",
    "alt_encoded = encoder.transform(alt_df.fillna('').values.flatten().reshape(-1, 1))\n",
    "\n",
    "# Obtener longitudes máximas\n",
    "max_len_REF = ref_df.shape[1]\n",
    "max_len_ALT = alt_df.shape[1]\n",
    "\n",
    "def reshape_encoded(encoded_data, max_len, nucleotides):\n",
    "    num_samples = encoded_data.shape[0] // (len(nucleotides) * max_len)\n",
    "    reshaped_data = encoded_data.reshape(num_samples, len(nucleotides) * max_len)\n",
    "    columns = [f'base_{base}_pos_{i}' for base in nucleotides for i in range(max_len)]\n",
    "    return pd.DataFrame(reshaped_data, columns=columns)\n",
    "\n",
    "# Volver a organizar los datos codificados\n",
    "encoded_REF_df = reshape_encoded(ref_encoded, max_len_REF, nucleotides)\n",
    "encoded_ALT_df = reshape_encoded(alt_encoded, max_len_ALT, nucleotides)\n",
    "\n",
    "# Concatenar con el DataFrame original y eliminar las columnas originales\n",
    "variaciones_encoded = pd.concat([variaciones, encoded_REF_df, encoded_ALT_df], axis=1)\n",
    "variaciones_encoded.drop(['REF', 'ALT'], axis=1, inplace=True)\n",
    "\n",
    "# Guardar el codificador para usarlo en futuros datos\n",
    "with open('one_hot_encoder.pkl', 'wb') as file:\n",
    "    pickle.dump(encoder, file)\n",
    "\n",
    "# Guardar el DataFrame resultante\n",
    "variaciones_encoded.to_csv('/home/ec2-user/SageMaker/segundo intento/final2/variaciones_encoded.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c291e67e-457a-4da1-85b4-c674a702355c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Longitud media de las secuencias en ALT: 1.5445407329598506\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Cargar tus datos en un DataFrame\n",
    "variaciones = pd.read_csv('/home/ec2-user/SageMaker/segundo intento/final2/variaciones.csv')\n",
    "\n",
    "# Obtener la columna de interés (ALT)\n",
    "ref_sequences = variaciones['REF']\n",
    "\n",
    "# Calcular la longitud de cada secuencia\n",
    "lengths = ref_sequences.apply(len)\n",
    "\n",
    "# Calcular la longitud media de las secuencias\n",
    "mean_length = lengths.mean()\n",
    "\n",
    "print(f\"Longitud media de las secuencias en ALT: {mean_length}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d309e1fd-136b-4efb-894e-77dadcf0efc9",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Longitud máxima de las secuencias en REF: 131\n",
      "Longitud máxima de las secuencias en ALT: 481\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 2467584 into shape (616896,524)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 52\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m pd\u001b[38;5;241m.\u001b[39mDataFrame(reshaped_data, columns\u001b[38;5;241m=\u001b[39mcolumns)\n\u001b[1;32m     51\u001b[0m \u001b[38;5;66;03m# Reorganizar los datos codificados para REF y ALT\u001b[39;00m\n\u001b[0;32m---> 52\u001b[0m encoded_REF_df \u001b[38;5;241m=\u001b[39m \u001b[43mreshape_encoded\u001b[49m\u001b[43m(\u001b[49m\u001b[43mref_encoded\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_len_REF\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnucleotides\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     53\u001b[0m encoded_ALT_df \u001b[38;5;241m=\u001b[39m reshape_encoded(alt_encoded, max_len_ALT, nucleotides)\n\u001b[1;32m     55\u001b[0m \u001b[38;5;66;03m# Concatenar con el DataFrame original\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[15], line 47\u001b[0m, in \u001b[0;36mreshape_encoded\u001b[0;34m(encoded_data, max_len, nucleotides)\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Reorganiza los datos codificados en un DataFrame.\"\"\"\u001b[39;00m\n\u001b[1;32m     46\u001b[0m num_samples \u001b[38;5;241m=\u001b[39m encoded_data\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m---> 47\u001b[0m reshaped_data \u001b[38;5;241m=\u001b[39m \u001b[43mencoded_data\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum_samples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mnucleotides\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmax_len\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     48\u001b[0m columns \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbase_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbase\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_pos_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m base \u001b[38;5;129;01min\u001b[39;00m nucleotides \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(max_len)]\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m pd\u001b[38;5;241m.\u001b[39mDataFrame(reshaped_data, columns\u001b[38;5;241m=\u001b[39mcolumns)\n",
      "\u001b[0;31mValueError\u001b[0m: cannot reshape array of size 2467584 into shape (616896,524)"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Cargar tus datos en un DataFrame\n",
    "variaciones = pd.read_csv('/home/ec2-user/SageMaker/segundo intento/final2/variaciones.csv')\n",
    "\n",
    "# Obtener las secuencias de REF y ALT\n",
    "ref_sequences = variaciones['REF']\n",
    "alt_sequences = variaciones['ALT']\n",
    "\n",
    "# Calcular la longitud máxima para cada columna\n",
    "max_len_REF = ref_sequences.apply(len).max()\n",
    "max_len_ALT = alt_sequences.apply(len).max()\n",
    "\n",
    "print(f\"Longitud máxima de las secuencias en REF: {max_len_REF}\")\n",
    "print(f\"Longitud máxima de las secuencias en ALT: {max_len_ALT}\")\n",
    "\n",
    "# Función para rellenar secuencias\n",
    "def pad_sequences(sequences, max_len, pad_char=' '):\n",
    "    \"\"\"Rellena las secuencias para que todas tengan la longitud max_len.\"\"\"\n",
    "    return [seq.ljust(max_len, pad_char) for seq in sequences]\n",
    "\n",
    "# Rellenar secuencias en REF y ALT con tamaños máximos separados\n",
    "ref_sequences_padded = pad_sequences(ref_sequences, max_len_REF)\n",
    "alt_sequences_padded = pad_sequences(alt_sequences, max_len_ALT)\n",
    "\n",
    "# Actualizar el DataFrame con las secuencias rellenas\n",
    "variaciones['REF'] = ref_sequences_padded\n",
    "variaciones['ALT'] = alt_sequences_padded\n",
    "\n",
    "# Definir nucleótidos\n",
    "nucleotides = ['A', 'C', 'G', 'T']\n",
    "\n",
    "# Codificador One-Hot para REF\n",
    "encoder_ref = OneHotEncoder(categories=[nucleotides], sparse_output=False, handle_unknown='ignore')\n",
    "ref_encoded = encoder_ref.fit_transform(np.array(ref_sequences_padded).reshape(-1, 1))\n",
    "\n",
    "# Codificador One-Hot para ALT\n",
    "encoder_alt = OneHotEncoder(categories=[nucleotides], sparse_output=False, handle_unknown='ignore')\n",
    "alt_encoded = encoder_alt.fit_transform(np.array(alt_sequences_padded).reshape(-1, 1))\n",
    "\n",
    "# Función para reorganizar datos codificados\n",
    "def reshape_encoded(encoded_data, max_len, nucleotides):\n",
    "    \"\"\"Reorganiza los datos codificados en un DataFrame.\"\"\"\n",
    "    num_samples = encoded_data.shape[0]\n",
    "    reshaped_data = encoded_data.reshape(num_samples, len(nucleotides) * max_len)\n",
    "    columns = [f'base_{base}_pos_{i}' for base in nucleotides for i in range(max_len)]\n",
    "    return pd.DataFrame(reshaped_data, columns=columns)\n",
    "\n",
    "# Reorganizar los datos codificados para REF y ALT\n",
    "encoded_REF_df = reshape_encoded(ref_encoded, max_len_REF, nucleotides)\n",
    "encoded_ALT_df = reshape_encoded(alt_encoded, max_len_ALT, nucleotides)\n",
    "\n",
    "# Concatenar con el DataFrame original\n",
    "final_df = pd.concat([variaciones, encoded_REF_df, encoded_ALT_df], axis=1)\n",
    "\n",
    "# Eliminar las columnas originales\n",
    "final_df = final_df.drop(columns=['REF', 'ALT'])\n",
    "\n",
    "# Guardar el DataFrame final en un archivo CSV\n",
    "final_df.to_csv('variaciones_preparadas.csv', index=False)\n",
    "\n",
    "print(\"El DataFrame final ha sido guardado en 'variaciones_preparadas.csv'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dacb0110-d0a6-43e2-aa07-dcc0a053c8fd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, MinMaxScaler\n",
    "import pickle\n",
    "\n",
    "# Cargar el archivo de variaciones\n",
    "variaciones = pd.read_csv('/home/ec2-user/SageMaker/segundo intento/final2/variaciones.csv')\n",
    "\n",
    "# Mapear valores X e Y a números en CHROM\n",
    "chrom_mapping = {str(i): i for i in range(1, 23)}\n",
    "chrom_mapping.update({'X': 50, 'Y': 100})\n",
    "variaciones['CHROM'] = variaciones['CHROM'].map(chrom_mapping)\n",
    "\n",
    "# Normalizar la columna CHROM\n",
    "scaler = MinMaxScaler()\n",
    "variaciones['CHROM_normalized'] = scaler.fit_transform(variaciones[['CHROM']])\n",
    "\n",
    "# Normalizar la columna Intervalo_POS\n",
    "intervalo_pos_scaler = MinMaxScaler()\n",
    "variaciones['Intervalo_POS_normalized'] = intervalo_pos_scaler.fit_transform(variaciones[['Intervalo_POS']])\n",
    "\n",
    "# Codificación de otras columnas\n",
    "label_encoders = {}\n",
    "categorical_cols = ['REF', 'ALT', 'gene', 'codingConsequence']\n",
    "\n",
    "for col in categorical_cols:\n",
    "    le = LabelEncoder()\n",
    "    variaciones[col + '_encoded'] = le.fit_transform(variaciones[col])\n",
    "    label_encoders[col] = le\n",
    "\n",
    "# Codificación One-Hot\n",
    "one_hot_cols = ['type', 'gene_strand', 'gene_boundaries']\n",
    "one_hot_encoder = OneHotEncoder(sparse_output=False, drop='first')\n",
    "encoded_categorical = one_hot_encoder.fit_transform(variaciones[one_hot_cols])\n",
    "encoded_categorical_df = pd.DataFrame(encoded_categorical, columns=one_hot_encoder.get_feature_names_out(one_hot_cols))\n",
    "\n",
    "# Concatenar todos los DataFrames codificados y transformados\n",
    "variaciones_encoded = pd.concat([variaciones, encoded_categorical_df], axis=1)\n",
    "variaciones_encoded.drop(one_hot_cols + categorical_cols, axis=1, inplace=True)\n",
    "\n",
    "# Guardar el DataFrame preprocesado en un archivo CSV\n",
    "variaciones_encoded.to_csv('/home/ec2-user/SageMaker/segundo intento/final2/variaciones_preprocesadas.csv', index=False)\n",
    "\n",
    "# Guardar los codificadores y el escalador\n",
    "with open('/home/ec2-user/SageMaker/segundo intento/final2/label_encoders.pkl', 'wb') as file:\n",
    "    pickle.dump(label_encoders, file)\n",
    "\n",
    "with open('/home/ec2-user/SageMaker/segundo intento/final2/one_hot_encoder.pkl', 'wb') as file:\n",
    "    pickle.dump(one_hot_encoder, file)\n",
    "\n",
    "with open('/home/ec2-user/SageMaker/segundo intento/final2/scaler.pkl', 'wb') as file:\n",
    "    pickle.dump(scaler, file)\n",
    "\n",
    "with open('/home/ec2-user/SageMaker/segundo intento/final2/intervalo_pos_scaler.pkl', 'wb') as file:\n",
    "    pickle.dump(intervalo_pos_scaler, file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e1ba63f2-4c0c-42f0-b84f-dfd17d622424",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   CHROM_normalized  Intervalo_POS_normalized  REF_encoded  ALT_encoded  \\\n",
      "0          0.040404                  0.315789         5415            1   \n",
      "1          0.040404                  0.315789         3586         1422   \n",
      "2          0.000000                  0.210526         3586            1   \n",
      "3          0.020202                  0.157895            0         1422   \n",
      "4          0.020202                  0.157895            0         2784   \n",
      "\n",
      "   gene_encoded  codingConsequence_encoded  type_SNP  gene_strand_-  \\\n",
      "0         15436                        107       1.0            0.0   \n",
      "1         15436                        107       1.0            0.0   \n",
      "2          3808                        109       1.0            0.0   \n",
      "3         21282                        109       1.0            0.0   \n",
      "4         21281                        109       1.0            0.0   \n",
      "\n",
      "   gene_strand_nan  gene_boundaries_within  gene_boundaries_nan  \n",
      "0              0.0                     1.0                  0.0  \n",
      "1              0.0                     1.0                  0.0  \n",
      "2              0.0                     1.0                  0.0  \n",
      "3              0.0                     1.0                  0.0  \n",
      "4              0.0                     1.0                  0.0  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 616896 entries, 0 to 616895\n",
      "Data columns (total 11 columns):\n",
      " #   Column                     Non-Null Count   Dtype  \n",
      "---  ------                     --------------   -----  \n",
      " 0   CHROM_normalized           616896 non-null  float64\n",
      " 1   Intervalo_POS_normalized   616896 non-null  float64\n",
      " 2   REF_encoded                616896 non-null  int64  \n",
      " 3   ALT_encoded                616896 non-null  int64  \n",
      " 4   gene_encoded               616896 non-null  int64  \n",
      " 5   codingConsequence_encoded  616896 non-null  int64  \n",
      " 6   type_SNP                   616896 non-null  float64\n",
      " 7   gene_strand_-              616896 non-null  float64\n",
      " 8   gene_strand_nan            616896 non-null  float64\n",
      " 9   gene_boundaries_within     616896 non-null  float64\n",
      " 10  gene_boundaries_nan        616896 non-null  float64\n",
      "dtypes: float64(7), int64(4)\n",
      "memory usage: 51.8 MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Cargar el DataFrame preprocesado\n",
    "variaciones_encoded = pd.read_csv('/home/ec2-user/SageMaker/segundo intento/final2/variaciones_preprocesadas.csv')\n",
    "variaciones_encoded.drop(columns=['CHROM', 'pacientes', 'Intervalo_POS'], inplace = True)\n",
    "variaciones_encoded.to_csv('/home/ec2-user/SageMaker/segundo intento/final2/variaciones_preprocesadas2.csv', index= False)\n",
    "# Verificar las primeras filas del DataFrame\n",
    "print(variaciones_encoded.head())\n",
    "\n",
    "# Comprobar las columnas y sus tipos de datos\n",
    "print(variaciones_encoded.info())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f13fc2d9-287c-43e8-b372-7dd2edf032c6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño de X: (307273, 15)\n",
      "Tamaño de y: (307273,)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, MinMaxScaler\n",
    "\n",
    "# Cargar el archivo de variaciones con etiquetas\n",
    "variaciones_con_etiqueta = pd.read_csv('/home/ec2-user/SageMaker/segundo intento/final2/variaciones_con_etiqueta.csv')\n",
    "\n",
    "# Cargar los codificadores y los escaladores\n",
    "with open('/home/ec2-user/SageMaker/segundo intento/final2/label_encoders.pkl', 'rb') as file:\n",
    "    label_encoders = pickle.load(file)\n",
    "\n",
    "with open('/home/ec2-user/SageMaker/segundo intento/final2/one_hot_encoder.pkl', 'rb') as file:\n",
    "    one_hot_encoder = pickle.load(file)\n",
    "\n",
    "with open('/home/ec2-user/SageMaker/segundo intento/final2/scaler.pkl', 'rb') as file:\n",
    "    scaler = pickle.load(file)\n",
    "\n",
    "with open('/home/ec2-user/SageMaker/segundo intento/final2/intervalo_pos_scaler.pkl', 'rb') as file:\n",
    "    intervalo_pos_scaler = pickle.load(file)\n",
    "\n",
    "# Mapear valores X e Y a números en CHROM\n",
    "chrom_mapping = {str(i): i for i in range(1, 23)}\n",
    "chrom_mapping.update({'X': 50, 'Y': 100})\n",
    "variaciones_con_etiqueta['CHROM'] = variaciones_con_etiqueta['CHROM'].map(chrom_mapping)\n",
    "\n",
    "# Normalizar CHROM y Intervalo_POS\n",
    "variaciones_con_etiqueta['CHROM_normalized'] = scaler.transform(variaciones_con_etiqueta[['CHROM']])\n",
    "variaciones_con_etiqueta['Intervalo_POS_normalized'] = intervalo_pos_scaler.transform(variaciones_con_etiqueta[['Intervalo_POS']])\n",
    "\n",
    "# Codificar columnas categóricas usando LabelEncoder\n",
    "for column in ['REF', 'ALT', 'gene', 'codingConsequence']:\n",
    "    le = label_encoders[column]\n",
    "    variaciones_con_etiqueta[f'{column}_encoded'] = le.transform(variaciones_con_etiqueta[column])\n",
    "\n",
    "# Codificar columnas categóricas usando OneHotEncoder\n",
    "one_hot_cols = ['type', 'gene_strand', 'gene_boundaries']\n",
    "encoded_categorical = one_hot_encoder.transform(variaciones_con_etiqueta[one_hot_cols])\n",
    "encoded_categorical_df = pd.DataFrame(encoded_categorical, columns=one_hot_encoder.get_feature_names_out(one_hot_cols))\n",
    "\n",
    "# Concatenar con las columnas codificadas\n",
    "variaciones_final = pd.concat([\n",
    "    variaciones_con_etiqueta.drop(columns=['CHROM', 'Intervalo_POS'] + one_hot_cols),\n",
    "    encoded_categorical_df\n",
    "], axis=1)\n",
    "\n",
    "# Separar características y etiquetas\n",
    "target_column = 'etiqueta'  # Reemplaza 'target_column_name' con el nombre real de la columna objetivo\n",
    "X = variaciones_final.drop(columns=[target_column])\n",
    "y = variaciones_final[target_column]\n",
    "\n",
    "# Guardar el DataFrame preprocesado en un archivo CSV\n",
    "variaciones_final.to_csv('/home/ec2-user/SageMaker/segundo intento/final2/variaciones_con_etiqueta_preprocesado.csv', index=False)\n",
    "\n",
    "# Verificar tamaños\n",
    "print(f\"Tamaño de X: {X.shape}\")\n",
    "print(f\"Tamaño de y: {y.shape}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3a606c45-df96-4fd1-ab8c-5d4618c07e6f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   etiqueta  CHROM_normalized  Intervalo_POS_normalized  REF_encoded  \\\n",
      "0         0          0.040404                  0.315789         5415   \n",
      "1         0          0.000000                  0.210526         3586   \n",
      "2         0          0.020202                  0.157895            0   \n",
      "3         0          0.020202                  0.157895            0   \n",
      "4         0          0.040404                  0.315789         3586   \n",
      "\n",
      "   ALT_encoded  gene_encoded  codingConsequence_encoded  type_SNP  \\\n",
      "0            1         15436                        107       1.0   \n",
      "1            1          3808                        109       1.0   \n",
      "2         1422         21282                        109       1.0   \n",
      "3         2784         21281                        109       1.0   \n",
      "4            1         15436                        107       1.0   \n",
      "\n",
      "   gene_strand_-  gene_strand_nan  gene_boundaries_within  gene_boundaries_nan  \n",
      "0            0.0              0.0                     1.0                  0.0  \n",
      "1            0.0              0.0                     1.0                  0.0  \n",
      "2            0.0              0.0                     1.0                  0.0  \n",
      "3            0.0              0.0                     1.0                  0.0  \n",
      "4            0.0              0.0                     1.0                  0.0  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 307273 entries, 0 to 307272\n",
      "Data columns (total 12 columns):\n",
      " #   Column                     Non-Null Count   Dtype  \n",
      "---  ------                     --------------   -----  \n",
      " 0   etiqueta                   307273 non-null  int64  \n",
      " 1   CHROM_normalized           307273 non-null  float64\n",
      " 2   Intervalo_POS_normalized   307273 non-null  float64\n",
      " 3   REF_encoded                307273 non-null  int64  \n",
      " 4   ALT_encoded                307273 non-null  int64  \n",
      " 5   gene_encoded               307273 non-null  int64  \n",
      " 6   codingConsequence_encoded  307273 non-null  int64  \n",
      " 7   type_SNP                   307273 non-null  float64\n",
      " 8   gene_strand_-              307273 non-null  float64\n",
      " 9   gene_strand_nan            307273 non-null  float64\n",
      " 10  gene_boundaries_within     307273 non-null  float64\n",
      " 11  gene_boundaries_nan        307273 non-null  float64\n",
      "dtypes: float64(7), int64(5)\n",
      "memory usage: 28.1 MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Cargar el DataFrame preprocesado\n",
    "variaciones_encoded = pd.read_csv('/home/ec2-user/SageMaker/segundo intento/final2/variaciones_con_etiqueta_preprocesado.csv')\n",
    "variaciones_encoded.drop(columns=['gene', 'REF', 'ALT', 'codingConsequence'], inplace = True)\n",
    "variaciones_encoded.to_csv('/home/ec2-user/SageMaker/segundo intento/final2/variaciones_con_etiqueta_preprocesado_2.csv', index= False)\n",
    "# Verificar las primeras filas del DataFrame\n",
    "print(variaciones_encoded.head())\n",
    "\n",
    "# Comprobar las columnas y sus tipos de datos\n",
    "print(variaciones_encoded.info())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "dad7dc6b-2eb0-4e53-b7e5-01bc74044c5d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n",
    "\n",
    "# Cargar el archivo de prueba\n",
    "variaciones_sin_etiqueta = pd.read_csv('/home/ec2-user/SageMaker/segundo intento/final2/variaciones_sin_etiqueta.csv')\n",
    "\n",
    "# Cargar los codificadores y el escalador\n",
    "with open('/home/ec2-user/SageMaker/segundo intento/final2/label_encoders.pkl', 'rb') as file:\n",
    "    label_encoders = pickle.load(file)\n",
    "\n",
    "with open('/home/ec2-user/SageMaker/segundo intento/final2/one_hot_encoder.pkl', 'rb') as file:\n",
    "    one_hot_encoder = pickle.load(file)\n",
    "\n",
    "with open('/home/ec2-user/SageMaker/segundo intento/final2/scaler.pkl', 'rb') as file:\n",
    "    scaler = pickle.load(file)\n",
    "\n",
    "with open('/home/ec2-user/SageMaker/segundo intento/final2/intervalo_pos_scaler.pkl', 'rb') as file:\n",
    "    intervalo_pos_scaler = pickle.load(file)\n",
    "\n",
    "# Mapear valores X e Y a números en CHROM\n",
    "chrom_mapping = {str(i): i for i in range(1, 23)}\n",
    "chrom_mapping.update({'X': 50, 'Y': 100})\n",
    "variaciones_sin_etiqueta['CHROM'] = variaciones_sin_etiqueta['CHROM'].map(chrom_mapping)\n",
    "\n",
    "# Normalizar las columnas CHROM e Intervalo_POS\n",
    "variaciones_sin_etiqueta['CHROM_normalized'] = scaler.transform(variaciones_sin_etiqueta[['CHROM']])\n",
    "variaciones_sin_etiqueta['Intervalo_POS_normalized'] = intervalo_pos_scaler.transform(variaciones_sin_etiqueta[['Intervalo_POS']])\n",
    "\n",
    "# Codificar columnas categóricas usando LabelEncoder\n",
    "categorical_cols = ['REF', 'ALT', 'gene', 'codingConsequence']\n",
    "for col in categorical_cols:\n",
    "    variaciones_sin_etiqueta[f'{col}_encoded'] = label_encoders[col].transform(variaciones_sin_etiqueta[col])\n",
    "\n",
    "# Codificar columnas categóricas usando OneHotEncoder\n",
    "one_hot_cols = ['type', 'gene_strand', 'gene_boundaries']\n",
    "encoded_categorical = one_hot_encoder.transform(variaciones_sin_etiqueta[one_hot_cols])\n",
    "encoded_categorical_df = pd.DataFrame(encoded_categorical, columns=one_hot_encoder.get_feature_names_out(one_hot_cols))\n",
    "\n",
    "# Concatenar todos los DataFrames codificados y transformados\n",
    "variaciones_preprocesadas = pd.concat([\n",
    "    variaciones_sin_etiqueta.drop(columns=['CHROM', 'Intervalo_POS', 'type', 'gene_strand', 'gene_boundaries'] + categorical_cols),\n",
    "    encoded_categorical_df\n",
    "], axis=1)\n",
    "\n",
    "# Guardar el DataFrame preprocesado en un archivo CSV\n",
    "variaciones_preprocesadas.to_csv('/home/ec2-user/SageMaker/segundo intento/final2/variaciones_preprocesadas_sin_etiqueta.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "be06f71e-289d-4063-9ea0-9cf41929f99f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   CHROM_normalized  Intervalo_POS_normalized  REF_encoded  ALT_encoded  \\\n",
      "0          0.040404                  0.315789         3586         1422   \n",
      "1          0.040404                  0.315789         3596         2796   \n",
      "2          0.040404                  0.315789         5415         1422   \n",
      "3          0.040404                  0.315789         5415         1422   \n",
      "4          0.040404                  0.315789         3586            1   \n",
      "\n",
      "   gene_encoded  codingConsequence_encoded  type_SNP  gene_strand_-  \\\n",
      "0         15436                        107       1.0            0.0   \n",
      "1         15436                        107       0.0            0.0   \n",
      "2         15436                        107       1.0            0.0   \n",
      "3         15436                        107       1.0            0.0   \n",
      "4          2735                        106       1.0            1.0   \n",
      "\n",
      "   gene_strand_nan  gene_boundaries_within  gene_boundaries_nan  \n",
      "0              0.0                     1.0                  0.0  \n",
      "1              0.0                     1.0                  0.0  \n",
      "2              0.0                     1.0                  0.0  \n",
      "3              0.0                     1.0                  0.0  \n",
      "4              0.0                     0.0                  0.0  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 309623 entries, 0 to 309622\n",
      "Data columns (total 11 columns):\n",
      " #   Column                     Non-Null Count   Dtype  \n",
      "---  ------                     --------------   -----  \n",
      " 0   CHROM_normalized           309623 non-null  float64\n",
      " 1   Intervalo_POS_normalized   309623 non-null  float64\n",
      " 2   REF_encoded                309623 non-null  int64  \n",
      " 3   ALT_encoded                309623 non-null  int64  \n",
      " 4   gene_encoded               309623 non-null  int64  \n",
      " 5   codingConsequence_encoded  309623 non-null  int64  \n",
      " 6   type_SNP                   309623 non-null  float64\n",
      " 7   gene_strand_-              309623 non-null  float64\n",
      " 8   gene_strand_nan            309623 non-null  float64\n",
      " 9   gene_boundaries_within     309623 non-null  float64\n",
      " 10  gene_boundaries_nan        309623 non-null  float64\n",
      "dtypes: float64(7), int64(4)\n",
      "memory usage: 26.0 MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Cargar el DataFrame preprocesado\n",
    "variaciones_encoded = pd.read_csv('/home/ec2-user/SageMaker/segundo intento/final2/variaciones_preprocesadas_sin_etiqueta.csv')\n",
    "#variaciones_encoded.drop(columns=['gene', 'REF', 'ALT', 'codingConsequence'], inplace = True)\n",
    "#variaciones_encoded.to_csv('/home/ec2-user/SageMaker/segundo intento/final2/variaciones_con_etiqueta_preprocesado_2.csv', index= False)\n",
    "# Verificar las primeras filas del DataFrame\n",
    "print(variaciones_encoded.head())\n",
    "\n",
    "# Comprobar las columnas y sus tipos de datos\n",
    "print(variaciones_encoded.info())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow2_p310",
   "language": "python",
   "name": "conda_tensorflow2_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
